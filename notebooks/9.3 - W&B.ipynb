{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i.imgur.com/gb6B4ig.png\" width=\"400\" alt=\"Weights & Biases\" />\n",
    "\n",
    "# –ß—Ç–æ —Ç–∞–∫–æ–µ W&B?\n",
    "\n",
    "`Weights & Biases (W&B)` - —ç—Ç–æ –º–Ω–æ–≥–æ—Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤, –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ–±–ª–µ–≥—á–∏—Ç—å –∏ —É—Å–∫–æ—Ä–∏—Ç—å —Ä—É—Ç–∏–Ω–Ω—ã–µ –ø—Ä–æ—Ü–µ—Å—Å—ã –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–µ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏\n",
    "\n",
    "* –ü–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–∏ –≤ —Ä–µ–∂–∏–º–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Å—Ä–∞–∑—É –∂–µ –≤—ã—è–≤–ª—è–π—Ç–µ –ø—Ä–æ–±–ª–µ–º–Ω—ã–µ –º–µ—Å—Ç–∞.\n",
    "* –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ - –≥—Ä–∞—Ñ–∏–∫–∏, –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è, –≤–∏–¥–µ–æ, –∞—É–¥–∏–æ, 3D-–æ–±—ä–µ–∫—Ç—ã –∏ –º–Ω–æ–≥–æ–µ [–¥—Ä—É–≥–æ–µ](https://docs.wandb.ai/guides/track/log#logging-objects).\n",
    "* –ü–æ–∑–≤–æ–ª—è–µ—Ç —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –º–æ–¥–µ–ª–∏ —Å —Ä–∞–∑–Ω—ã—Ö —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –∏ —Ö—Ä–∞–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ –æ–¥–Ω–æ–º –º–µ—Å—Ç–µ, —Ç–∞–∫ –∂–µ —É–¥–æ–±–Ω–æ –ø—Ä–∏ –∫–æ–º–∞–Ω–¥–Ω–æ–π —Ä–∞–±–æ—Ç–µ –Ω–∞–¥ –∑–∞–¥–∞—á–µ–π\n",
    "* –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤ W&B –ø–æ–∑–≤–æ–ª—è–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å –∏ —Å–æ–∑–¥–∞–≤–∞—Ç—å –≤–µ—Ä—Å–∏–∏ –≤–∞—à–∏—Ö –Ω–∞–±–æ—Ä–æ–≤ –¥–∞–Ω–Ω—ã—Ö, –º–æ–¥–µ–ª–µ–π, –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –∫–æ–Ω–≤–µ–π–µ—Ä–∞—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è.\n",
    "* –ù–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ –≤—Ö–æ–¥–∞ (–º–æ–∂–Ω–æ –Ω–∞—á–∞—Ç—å —Å 6 —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞), —Ç–∞–∫ –∂–µ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ —Å–æ –≤—Å–µ–º–∏ –ø–æ–ø—É–ª—è—Ä–Ω—ã–º–∏ DS —Ñ—Ä–µ–π–º–≤–æ—Ä–∫–∞–º–∏\n",
    "\n",
    "![centralized dashboard](https://i.imgur.com/BGgfZj3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –£—Å—Ç–∞–Ω–æ–≤–∫–∞ `wandb`\n",
    "\n",
    "`wandb` (–±–∏–±–ª–∏–æ—Ç–µ–∫–∞ W&B), –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –Ω–∞ Kaggl–µ\n",
    "\n",
    "–ü–æ—Å–∫–æ–ª—å–∫—É –æ–±—Ä–∞–∑ kaggle –Ω–µ —á–∞—Å—Ç–æ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è, –∞ `wandb` –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –≤—ã–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–µ –≤–µ—Ä—Å–∏–∏,—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω—é—é –≤–µ—Ä—Å–∏—é —Å –ø–æ–º–æ—â—å—é —Ñ–ª–∞–≥–∞ `--upgrade`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade -q wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è —É—á–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏ –∏ –≤—Ö–æ–¥ –≤ —Å–∏—Å—Ç–µ–º—É\n",
    "\n",
    "–í–∞–º –ø–æ–Ω–∞–¥–æ–±–∏—Ç—Å—è —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –∫–ª—é—á API –¥–ª—è –≤—Ö–æ–¥–∞ –≤ Weights & Biases.\n",
    "\n",
    "1. –ï—Å–ª–∏ —É –≤–∞—Å –Ω–µ—Ç —É—á–µ—Ç–Ω–æ–π –∑–∞–ø–∏—Å–∏ Weights & Biases, –≤—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–π—Ç–∏ –Ω–∞ https://wandb.ai/site –∏ —Å–æ–∑–¥–∞—Ç—å –ë–ï–°–ü–õ–ê–¢–ù–£–Æ —É—á–µ—Ç–Ω—É—é –∑–∞–ø–∏—Å—å.\n",
    "2. –î–æ—Å—Ç—É–ø –∫ –∫–ª—é—á—É API: https://wandb.ai/authorize.\n",
    "\n",
    "–ù–∞ Kaggle –º–æ–∂–Ω–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞—Ç—å—Å—è –≤ W&B –¥–≤—É–º—è —Å–ø–æ—Å–æ–±–∞–º–∏:\n",
    "\n",
    "1. –° –ø–æ–º–æ—â—å—é `wandb.login ()`. –û–Ω –∑–∞–ø—Ä–æ—Å–∏—Ç –∫–ª—é—á API, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –º–æ–∂–µ—Ç–µ —Å–∫–æ–ø–∏—Ä–æ–≤–∞—Ç—å + –≤—Å—Ç–∞–≤–∏—Ç—å.\n",
    "2. –ò—Å–ø–æ–ª—å–∑—É—è Kaggle secrets –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∫–ª—é—á–∞ API –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã–π –Ω–∏–∂–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç –∫–æ–¥–∞ –¥–ª—è –≤—Ö–æ–¥–∞ –≤ —Å–∏—Å—Ç–µ–º—É. –ü—Ä–æ—á—Ç–∏—Ç–µ —ç—Ç–æ [–æ–±—Å—É–∂–¥–µ–Ω–∏–µ](https://www.kaggle.com/product-feedback/114053), —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ Kaggle secrets.\n",
    "\n",
    "```python\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "wandb_api = user_secrets.get_secret(\"wandb_api\") \n",
    "wandb.login(key=wandb_api)\n",
    "```\n",
    "[–ü–æ–¥—Ä–æ–±–Ω–µ–µ –æ –≤—Ö–æ–¥–µ –≤ W&B](https://docs.wandb.ai/ref/cli/wandb-login)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mivanich\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í–æ–∑—å–º–µ–º, –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞, —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—é `MLP` –∏–∑ —Ä–∞–∑–¥–µ–ª–∞ –ø—Ä–æ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª—ã –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "car_info = pd.read_csv('../data/car_info.csv')   # car_info - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ –º–∞—à–∏–Ω—ã —Å —Ç–∞—Ä–≥–µ—Ç–æ–º\n",
    " \n",
    "rides_info = pd.read_csv('../data/rides_info.csv') # rides_info - –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø—Ä–æ –ø–æ–µ–∑–¥–∫–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_info = rides_info.merge(car_info, on = 'car_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_cols = ['user_id', 'car_id', 'ride_id', 'ride_date']\n",
    "cat_cols = ['car_type', 'fuel_type', 'model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_117170/3567080960.py:5: FutureWarning: The default value of numeric_only in DataFrame.median is deprecated. In a future version, it will default to False. In addition, specifying 'numeric_only=None' is deprecated. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
      "  rides_info.fillna(rides_info.median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# –∑–∞–∫–æ–¥–∏—Ä—É–µ–º –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ —Ñ–∏—á–∏ –≤ one hot encoding –≤–µ–∫—Ç–æ—Ä–∞\n",
    "rides_info = pd.get_dummies(rides_info, columns=cat_cols)\n",
    "\n",
    "# –∑–∞–ø–æ–ª–Ω–∏–º –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ–¥–∏–∞–Ω–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –ø–æ —Å—Ç–æ–ª–±—Ü—É\n",
    "rides_info.fillna(rides_info.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rides_df = rides_info.drop(columns=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ø–µ—Ä–µ–≤–µ–¥–µ–º —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω–æ–≥–æ —Ç–∞—Ä–≥–µ—Ç–∞ –≤ —Ü–µ–ª–æ—á–∏—Å–ª–µ–Ω–Ω—ã–µ\n",
    "le = LabelEncoder()\n",
    "rides_df['target_class'] = le.fit_transform(rides_df['target_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# —á–∏—Å–ª–æ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–≤–µ—Ä–≥–Ω–µ–º —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏\n",
    "num_cols = [col for col in list(rides_df.columns)\n",
    "            if col not in ['target_reg', 'target_class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "df = scaler.fit_transform(rides_info[num_cols])\n",
    "df = pd.DataFrame(df, columns=num_cols)\n",
    "\n",
    "target_scaler = RobustScaler()\n",
    "target = target_scaler.fit_transform(rides_info['target_reg'].values.reshape(-1, 1))\n",
    "\n",
    "df['target_reg'] = target\n",
    "df['target_class'] = rides_info['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –í–ê–ñ–ù–û! - —Ñ–∏–∫—Å–∏—Ä—É–µ–º –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç—å\n",
    "def seed_everything(seed=42):\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –¥–ª—è –Ω–∞—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ —Ä–∞–∑–º–µ—Ä–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –ø–æ–¥–æ–π–¥–µ—Ç –∑–∞–ø—É—Å–∫ –Ω–∞ cpu\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –°–æ—Ö—Ä–∞–Ω—è–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤ –≤–∏–¥–µ —Å–ª–æ–≤–∞—Ä—è, –¥–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –ø–æ–∑–∂–µ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ñ–∞–π–ª –≤ W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "\n",
    "CONFIG = dict (\n",
    "    hidden_size=128,\n",
    "    dropout=0.1,\n",
    "    lr=1e-3,\n",
    "    batch_size=128,\n",
    "    num_workers=os.cpu_count(),\n",
    "    epochs=10,\n",
    "    num_features=train.shape[1]-2, # –∫–æ–ª-–≤–æ —Ñ–∏—á–µ–π –ø–æ–¥–∞–≤–∞–µ–º–æ–µ –Ω–∞ –≤—Ö–æ–¥\n",
    "    num_tar_2=train.target_class.nunique(), # –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—Ö–æ–¥–æ–≤ —Ä–∞–≤–Ω–æ –∫–æ–ª-–≤—É –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ–º—ã—Ö –∫–ª–∞—Å—Å–æ–≤\n",
    "    architecture = \"MLP\",\n",
    "    infra = \"Kaggle\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  –°—Ç—Ä–æ–∏–º –≤—Ö–æ–¥–Ω–æ–π –∫–æ–Ω–≤–µ–π–µ—Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –¥–∞—Ç–∞—Å–µ—Ç –≤—ã–¥–∞–µ—Ç —Ñ–∏—á–∏ –∏ –∑–Ω–∞—á–µ–Ω–∏—è —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö\n",
    "class Rides(Dataset):\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx,:]\n",
    "        \n",
    "        data = row.drop(labels=['target_reg', 'target_class'])\n",
    "        \n",
    "        data = torch.FloatTensor(data.values.astype('float'))\n",
    "        tar_1 = torch.tensor(row['target_reg']).float()\n",
    "        tar_2 = row['target_class'].astype('int')\n",
    "        \n",
    "        return data, tar_1, tar_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build data loaders\n",
    "\n",
    "train_datasets = {'train': Rides(train),\n",
    "                  'val': Rides(test)}\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(train_datasets[x], \n",
    "                                                   batch_size=CONFIG['batch_size'], \n",
    "                                                   shuffle=True, \n",
    "                                                   num_workers=CONFIG['num_workers'])\n",
    "                    for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –º–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ü–æ—Å—Ç—Ä–æ–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É mlp —Å –¥–≤—É–º—è –≥–æ–ª–æ–≤–∞–º–∏ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∫–∞—Ü–∏–∏\n",
    "\n",
    "class TabularNN(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "                          nn.Linear(cfg['num_features'], cfg['hidden_size']),\n",
    "                          nn.Dropout(cfg['dropout']),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(cfg['hidden_size'], cfg['hidden_size']),\n",
    "                          nn.Dropout(cfg['dropout']),\n",
    "                          nn.ReLU(),\n",
    "                          nn.Linear(cfg['hidden_size'], cfg['hidden_size'] // 2),\n",
    "                          )\n",
    "        \n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(cfg['hidden_size'] // 2, 1)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(cfg['hidden_size'] // 2, cfg['num_tar_2'])\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = self.mlp(data)\n",
    "        tar1 = self.regressor(x)\n",
    "        tar2 = self.classifier(x)\n",
    "        return tar1.view(-1), tar2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–∞–µ–º –∏ –ª–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ W&B\n",
    "\n",
    "–í —ç—Ç–æ–º —Ä–∞–∑–¥–µ–ª–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å:\n",
    "\n",
    "* [`wandb.init()`](https://docs.wandb.ai/guides/track/launch): –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –Ω–æ–≤—ã–π –∑–∞–ø—É—Å–∫.\n",
    "* [`wandb.finish()`](https://docs.wandb.ai/ref/python/finish):  –∑–∞–≤–µ—Ä—à–∏—Ç—å –∏ –∑–∞–∫—Ä—ã—Ç—å –ø—Ä–æ–±–µ–≥.\n",
    "* [`wandb.config`](https://docs.wandb.ai/guides/track/config): –æ–±—ä–µ–∫—Ç, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ö—Ä–∞–Ω—è—Ç—Å—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∑–∞–ø—É—Å–∫–æ–º.\n",
    "\n",
    "\n",
    "Run (–∏–ª–∏ [–æ–±—ä–µ–∫—Ç wandb.Run](https://docs.wandb.ai/ref/python/run)) - —ç—Ç–æ –µ–¥–∏–Ω–∏—Ü–∞ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è W&B, –æ–±—ã—á–Ω–æ —ç—Ç–æ 1 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "model = TabularNN(CONFIG).to(device)\n",
    "\n",
    "# –æ–ø—Ç–∏–º–∞–π–∑–µ—Ä –∏ –ª–æ—Å—Å—ã –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = CONFIG['lr'])\n",
    "regression_criterion = nn.MSELoss().to(device)\n",
    "classification_criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ò—Å–ø–æ–ª—å–∑—É–µ–º `wandb.init ()` –¥–ª—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ W&B.\n",
    "\n",
    "–í \"pipeline\" –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤—ã –º–æ–∂–µ—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å `wandb.init ()` –≤ –Ω–∞—á–∞–ª–æ –æ–±—É—á–∞—é—â–µ–≥–æ —Å—Ü–µ–Ω–∞—Ä–∏—è, –∞ —Ç–∞–∫–∂–µ —Å—Ü–µ–Ω–∞—Ä–∏–π –æ—Ü–µ–Ω–∫–∏, –∏ –∫–∞–∂–¥–∞—è —á–∞—Å—Ç—å –±—É–¥–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞—Ç—å—Å—è –∫–∞–∫ –∑–∞–ø—É—Å–∫ –≤ W&B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training configuration:  {'hidden_size': 128, 'dropout': 0.1, 'lr': 0.001, 'batch_size': 128, 'num_workers': 32, 'epochs': 10, 'num_features': 46, 'num_tar_2': 9, 'architecture': 'MLP', 'infra': 'Kaggle', 'model_name': 'Tabular_NN'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/storage/Aleron/Course/Competitive_Data_Science/notebooks/wandb/run-20230424_130947-7npv8nzq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ivanich/Course%20contest/runs/7npv8nzq' target=\"_blank\">smooth-leaf-23</a></strong> to <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ivanich/Course%20contest/runs/7npv8nzq' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/7npv8nzq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –î–æ–±–∞–≤–∏–º –≤ CONFIG –∏–º—è –º–æ–¥–µ–ª–∏\n",
    "CONFIG['model_name'] = 'Tabular_NN'\n",
    "print('Training configuration: ', CONFIG)\n",
    "\n",
    "# Initialize W&B run\n",
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\",\n",
    "                 config=CONFIG,\n",
    "                 group='MLP', \n",
    "                 job_type='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–ø–æ–ª—å–∑—É–µ–º—ã–µ –∞—Ä–≥—É–º–µ–Ω—Ç—ã `wandb.init ()`:\n",
    "\n",
    "* `project`: —ç—Ç–æ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –∏–º—è –ø—Ä–æ–µ–∫—Ç–∞ W&B, –≤ –∫–æ—Ç–æ—Ä—ã–π –æ—Ç–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è –∑–∞–ø—É—Å–∫. –°–æ–∑–¥–∞–µ–º –Ω–∞ –ø–ª–∞—Ç—Ñ–æ—Ä–º–µ W&B –Ω–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç —Å –Ω–∞–∑–≤–∞–Ω–∏–µ–º ¬´CDSC_DataFeeling_contest¬ª –∏ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –Ω–µ–≥–æ run.\n",
    "\n",
    "* `config`: —ç—Ç–æ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç `wandb.config`, –æ–±—ä–µ–∫—Ç, –ø–æ–¥–æ–±–Ω—ã–π —Å–ª–æ–≤–∞—Ä—é, –≤ –∫–æ—Ç–æ—Ä–æ–º —Ö—Ä–∞–Ω—è—Ç—Å—è –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã, –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤–≤–æ–¥–∞ –∏ –¥—Ä—É–≥–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ.\n",
    "\n",
    "* `group`: —ç—Ç–æ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø—Ä–æ–≥–æ–Ω–æ–≤, —á—Ç–æ–±—ã –±—ã–ª–æ –ª–µ–≥—á–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –ø—Ä–æ–≥–æ–Ω—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä.\n",
    "\n",
    "* `job_type`: —ç—Ç–æ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç —É–∫–∞–∑—ã–≤–∞–µ—Ç —Ç–∏–ø –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è, –Ω–∞–ø—Ä–∏–º–µ—Ä, ¬´`train`¬ª –∏–ª–∏ ¬´`evaluate`¬ª. –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∏–ø–∞ run —É–ø—Ä–æ—â–∞–µ—Ç –ø–æ—Å–ª–µ–¥—É—é—â—É—é —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—é –∏ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫—É run, –Ω–∞–ø—Ä–∏–º–µ—Ä, —á—Ç–æ–±—ã —Å—Ä–∞–≤–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ ¬´`train`¬ª run-–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±–Ω–æ–≤–ª—è–µ–º `wandb.config` \n",
    "\n",
    "–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏ –ø–æ–ª–µ–∑–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è –≤–∞—à–µ–π —Ä–∞–±–æ—Ç—ã –ø–æ–∑–∂–µ. –° –ø–æ–º–æ—â—å—é W&B –≤—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∞—Ç—å run-—ã –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏, —á—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –≤—ã –º–æ–∂–µ—Ç–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ä–∞–∑–Ω—ã—Ö run-–æ–≤ –∏ –≤–∏–¥–µ—Ç—å, –∫–∞–∫ –æ–Ω–∏ –≤–ª–∏—è—é—Ç –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
    "\n",
    "–ï—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–ø–æ—Å–æ–±–æ–≤ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å `wandb.config`:\n",
    "\n",
    "* –ó–∞–¥–∞—Ç—å `wandb.config` —Å –∞—Ä–≥—É–º–µ–Ω—Ç–æ–º `wandb.init (config)`, –∫–∞–∫ —É–∫–∞–∑–∞–Ω–æ –≤—ã—à–µ.\n",
    "* –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `wandb.config` –Ω–∞–ø—Ä—è–º—É—é.\n",
    "* –°–º. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤ —ç—Ç–æ–º [Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-log/Configs_in_W%26B.ipynb#scrollTo=xFf3zjBSixC1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">smooth-leaf-23</strong> at: <a href='https://wandb.ai/ivanich/Course%20contest/runs/7npv8nzq' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/7npv8nzq</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230424_130947-7npv8nzq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add \"type\" and \"kaggle_competition\" to `wandb.config` directly\n",
    "wandb.config.type = 'baseline'\n",
    "wandb.config.kaggle_competition = 'Competitive Data Science Course by Data Feeling'\n",
    "\n",
    "# Close W&B run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–≤–µ–¥–µ–º —Å–µ—Ä–∏—é –∏–∑ 5 —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤ –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ `dropout rate`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# –ò–∑–º–µ–Ω–∏–º CONFIG - –æ–ø—Ä–µ–¥–µ–ª–∏–º dropout –∫–∞–∫ —Ä–∞–Ω–¥–æ–º–Ω—É—é –≤–µ–ª–∏—á–∏–Ω—É –≤ –∑–∞–¥–∞–Ω–Ω–æ–º –¥–∏–∞–ø–∞–∑–æ–Ω–µ –∑–Ω–∞—á–µ–Ω–∏–π\n",
    "import random\n",
    "\n",
    "CONFIG['dropout'] = random.uniform(0.01, 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "385abf88281a44848534563488cafdc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01666812083373467, max=1.0)‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/storage/Aleron/Course/Competitive_Data_Science/notebooks/wandb/run-20230424_130959-1ljkabm6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ivanich/Course%20contest/runs/1ljkabm6' target=\"_blank\">northern-fog-24</a></strong> to <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ivanich/Course%20contest/runs/1ljkabm6' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/1ljkabm6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_117170/4292527571.py\", line 17, in __getitem__\n    tar_2 = row['target_class'].astype('int')\nAttributeError: 'str' object has no attribute 'astype'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Iterate over data.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels_1, labels_2 \u001b[38;5;129;01min\u001b[39;00m dataloaders[phase]:\n\u001b[1;32m     31\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m     labels_1 \u001b[38;5;241m=\u001b[39m labels_1\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 628\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    632\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1333\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1333\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/utils/data/dataloader.py:1359\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1359\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/_utils.py:543\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m--> 543\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mAttributeError\u001b[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py\", line 302, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\", line 58, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/ipykernel_117170/4292527571.py\", line 17, in __getitem__\n    tar_2 = row['target_class'].astype('int')\nAttributeError: 'str' object has no attribute 'astype'\n"
     ]
    }
   ],
   "source": [
    "num_epochs = CONFIG['epochs']\n",
    "for _ in range(5):\n",
    "    # üêù initialise a wandb run\n",
    "    wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\", \n",
    "                config=CONFIG,\n",
    "                group='MLP', \n",
    "                job_type='train'\n",
    "            )\n",
    "    \n",
    "    val_acc_history = []\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_loss = 100000.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels_1, labels_2 in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels_1 = labels_1.to(device)\n",
    "                labels_2 = labels_2.to(device)\n",
    "                \n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # Get model outputs and calculate loss\n",
    "\n",
    "                    outputs_1, outputs_2 = model(inputs)\n",
    "                    loss_1 = regression_criterion(outputs_1, labels_1)\n",
    "                    loss_2 = classification_criterion(outputs_2, labels_2)\n",
    "\n",
    "                    loss = loss_1 + loss_2\n",
    "\n",
    "                    _, preds_2 = torch.max(outputs_2, 1)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                val_acc_history.append(running_loss)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
    "            print('{} Loss: {:.4f}'.format(phase, epoch_loss))\n",
    "            \n",
    "            # üêù Log train and validation metrics to wandb\n",
    "            wandb.log({'{} loss'.format(phase): epoch_loss})\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_loss < best_loss:\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    # üêù Close your wandb run \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `run.finish ()`, —á—Ç–æ–±—ã –∑–∞–∫—Ä—ã—Ç—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π run W&B –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è `job_type`.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*–ö–∞–∂–¥—ã–π run –ø–æ–ª—É—á–∞–µ—Ç —Å–≤–æ—é —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É, –Ω–∞ –≤–∫–ª–∞–¥–∫–∞—Ö –∫–æ—Ç–æ—Ä–æ–π —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∑–∞–ø—É—Å–∫–µ.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–æ–∑–¥–∞–Ω–∏–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ W&B.\n",
    "\n",
    "W&B Artifacts –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∞–º —Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ –≤—Ö–æ–¥—è—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö) –∏ –≤—ã—Ö–æ–¥—è—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, –≤–µ—Å–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏) —ç—Ç–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ–≤.\n",
    "\n",
    "–î—Ä—É–≥–∏–º–∏ —Å–ª–æ–≤–∞–º–∏, –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã - —ç—Ç–æ —Å–ø–æ—Å–æ–± —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–∞—à–∏ –Ω–∞–±–æ—Ä—ã –¥–∞–Ω–Ω—ã—Ö –∏ –º–æ–¥–µ–ª–∏. –í—ã –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å [—ç—Ç–æ—Ç Colab](https://colab.research.google.com/github/wandb/examples/blob/master/colabs/wandb-artifacts/Pipeline_Versioning_with_W%26B_Artifacts.ipynb), —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ–± –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞—Ö.\n",
    "\n",
    "### –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ—é —Ä–∞–±–æ—Ç—É —Å –ø–æ–º–æ—â—å—é `wandb.log_artifact ()` \n",
    "\n",
    "–í run –µ—Å—Ç—å —Ç—Ä–∏ —à–∞–≥–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–∞ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "1. –°–æ–∑–¥–∞–π—Ç–µ –ø—É—Å—Ç–æ–π –∞—Ä—Ç–µ—Ñ–∞–∫—Ç —Å –ø–æ–º–æ—â—å—é `wandb.Artifact ()`.\n",
    "2. –î–æ–±–∞–≤—å—Ç–µ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ –≤ –ê—Ä—Ç–µ—Ñ–∞–∫—Ç —Å –ø–æ–º–æ—â—å—é `wandb.add_file ()`.\n",
    "3. –í—ã–∑–æ–≤–∏—Ç–µ `wandb.log_artifact ()`, —á—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ê—Ä—Ç–µ—Ñ–∞–∫—Ç."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), 'tab_model.pth')\n",
    "\n",
    "# Initialize a new W&B run\n",
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\", \n",
    "                config=CONFIG,\n",
    "                group='MLP', \n",
    "                 job_type='save') # Note the job_type\n",
    "\n",
    "# Update `wandb.config`\n",
    "wandb.config.type = 'baseline'\n",
    "wandb.config.kaggle_competition = 'Competitive Data Science Course by Data Feeling'\n",
    "\n",
    "# Save model as Model Artifact\n",
    "artifact = wandb.Artifact(name='best_tab_NN', type='model') # –ó–∞–¥–∞–µ–º –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ –∏–º—è\n",
    "artifact.add_file('tab_model.pth')\n",
    "run.log_artifact(artifact)\n",
    "\n",
    "# Finish W&B run\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–µ–ø–µ—Ä—å –∑–∞–ª–æ–≥–∏—Ä—É–µ–º –±—É—Å—Ç–∏–Ω–≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import json\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1ljkabm6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">northern-fog-24</strong> at: <a href='https://wandb.ai/ivanich/Course%20contest/runs/1ljkabm6' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/1ljkabm6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230424_130959-1ljkabm6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:1ljkabm6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb01705488b3415f889e15623db9fd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.016668017068877817, max=1.0‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/storage/Aleron/Course/Competitive_Data_Science/notebooks/wandb/run-20230424_131348-vv619c6y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ivanich/Course%20contest/runs/vv619c6y' target=\"_blank\">fearless-fog-25</a></strong> to <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ivanich/Course%20contest' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ivanich/Course%20contest/runs/vv619c6y' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/vv619c6y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project='Course contest',\n",
    "                 entity=\"ivanich\",\n",
    "                 job_type='train-model',\n",
    "                 group='XGB',\n",
    "                 config={'wandb_nb':'wandb_course_contest'})  # config is optional here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst_params = {\n",
    "         'gamma': 1,               ## def: 0\n",
    "         'learning_rate': 0.1,     ## def: 0.1\n",
    "        'max_depth': 3,\n",
    "        'min_child_weight': 100,  ## def: 1\n",
    "        'n_estimators': 25,\n",
    "        'nthread': 4,\n",
    "        'random_state': 42,\n",
    "        'reg_alpha': 0,\n",
    "        'reg_lambda': 0,          ## def: 1\n",
    "        'eval_metric': [ 'mlogloss'],\n",
    "        'tree_method': 'hist'  # use `gpu_hist` to train on GPU\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.config.update(dict(bst_params))\n",
    "run.config.update({'early_stopping_rounds': 40})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['target_reg','target_class'], axis=1)\n",
    "y = rides_df['target_class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í `wandb` –µ—Å—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ XGBoost —á–µ—Ä–µ–∑ callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 2.12266\n",
      "Training until validation scores don't improve for 40 rounds\n",
      "[2]\tvalid_0's multi_logloss: 2.07981\n",
      "[3]\tvalid_0's multi_logloss: 2.0463\n",
      "[4]\tvalid_0's multi_logloss: 2.01899\n",
      "[5]\tvalid_0's multi_logloss: 1.99613\n",
      "[6]\tvalid_0's multi_logloss: 1.97649\n",
      "[7]\tvalid_0's multi_logloss: 1.95974\n",
      "[8]\tvalid_0's multi_logloss: 1.94527\n",
      "[9]\tvalid_0's multi_logloss: 1.9326\n",
      "[10]\tvalid_0's multi_logloss: 1.92094\n",
      "[11]\tvalid_0's multi_logloss: 1.91083\n",
      "[12]\tvalid_0's multi_logloss: 1.9013\n",
      "[13]\tvalid_0's multi_logloss: 1.8926\n",
      "[14]\tvalid_0's multi_logloss: 1.88489\n",
      "[15]\tvalid_0's multi_logloss: 1.87779\n",
      "[16]\tvalid_0's multi_logloss: 1.87106\n",
      "[17]\tvalid_0's multi_logloss: 1.86467\n",
      "[18]\tvalid_0's multi_logloss: 1.85874\n",
      "[19]\tvalid_0's multi_logloss: 1.84907\n",
      "[20]\tvalid_0's multi_logloss: 1.84341\n",
      "[21]\tvalid_0's multi_logloss: 1.83864\n",
      "[22]\tvalid_0's multi_logloss: 1.83376\n",
      "[23]\tvalid_0's multi_logloss: 1.82731\n",
      "[24]\tvalid_0's multi_logloss: 1.82192\n",
      "[25]\tvalid_0's multi_logloss: 1.81685\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[25]\tvalid_0's multi_logloss: 1.81685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x7f4c6cccceb0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "import lightgbm as lgb\n",
    "\n",
    "xgbmodel = lgb.LGBMClassifier(**bst_params, use_label_encoder=False)\n",
    "\n",
    "# Train the model, using the wandb_callback for logging\n",
    "xgbmodel.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "             early_stopping_rounds=run.config['early_stopping_rounds'],\n",
    "             callbacks=[wandb_callback()])\n",
    "\n",
    "bstr = xgbmodel.booster_\n",
    "bstr.save_model(\"lgb.mod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.xgboost import wandb_callback\n",
    "\n",
    "# Initialize the XGBoostClassifier\n",
    "xgbmodel = xgboost.XGBClassifier(**bst_params, use_label_encoder=False)\n",
    "\n",
    "# Train the model, using the wandb_callback for logging\n",
    "xgbmodel.fit(X_train, y_train, eval_set=[(X_test, y_test)], \n",
    "             early_stopping_rounds=run.config['early_stopping_rounds'],\n",
    "             callbacks=[wandb_callback()])\n",
    "\n",
    "bstr = xgbmodel.get_booster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the booster to disk\n",
    "model_name = f'{run.name}_model.json'\n",
    "bstr.save_model(model_name)\n",
    "\n",
    "# Get the booster's config\n",
    "#config = json.loads(bstr.save_config())\n",
    "\n",
    "# Log the trained model to W&B Artifacts, including the booster's config\n",
    "model_art = wandb.Artifact(name=model_name, type='model',) #metadata=dict(config))\n",
    "model_art.add_file(model_name)\n",
    "run.log_artifact(model_art);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log booster metrics\n",
    "run.summary[\"best_score\"] = bstr.best_score\n",
    "run.summary[\"best_iteration\"] = bstr.best_iteration\n",
    "#run.summary[\"best_ntree_limit\"] = bstr.best_ntree_limit\n",
    "\n",
    "# Log validation metrics\n",
    "preds = xgbmodel.predict(X_test)\n",
    "run.summary[\"f1_score\"] = f1_score(y_test, preds, average='macro')\n",
    "run.summary[\"accuracy\"] = accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finish the W&B Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>iteration</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñà</td></tr><tr><td>valid_0_multi_logloss</td><td>‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.32011</td></tr><tr><td>best_iteration</td><td>25</td></tr><tr><td>f1_score</td><td>0.31565</td></tr><tr><td>iteration</td><td>24</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fearless-fog-25</strong> at: <a href='https://wandb.ai/ivanich/Course%20contest/runs/vv619c6y' target=\"_blank\">https://wandb.ai/ivanich/Course%20contest/runs/vv619c6y</a><br/>Synced 6 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230424_131348-vv619c6y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ‚ùÑÔ∏è –†–µ—Å—É—Ä—Å—ã\n",
    "\n",
    "–í–æ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Å—Å—ã–ª–æ–∫ –ø–æ —Ç–µ–º–µ:\n",
    "\n",
    "\n",
    "* –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å [–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ–π –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏–µ–π](https://docs.wandb.ai/), —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –±–æ–ª—å—à–µ –æ –ø–µ—Ä–µ–¥–æ–≤—ã—Ö –º–µ—Ç–æ–¥–∞—Ö —Ä–∞–±–æ—Ç—ã –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ—É–Ω–∫—Ü–∏—è—Ö.\n",
    "\n",
    "* –û–∑–Ω–∞–∫–æ–º—å—Ç–µ—Å—å —Å [—Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–µ–º GitHub —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏](https://github.com/wandb/examples), –≥–¥–µ –≤—ã –Ω–∞–π–¥–µ—Ç–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ –æ—Ç–æ–±—Ä–∞–Ω–Ω—ã–µ –∏ –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã. –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ö–æ—Ä–æ—à–µ–π –æ—Ç–ø—Ä–∞–≤–Ω–æ–π —Ç–æ—á–∫–æ–π.\n",
    "\n",
    "–í–æ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –¥—Ä—É–≥–∏–µ Kaggle –Ω–æ—É—Ç–±—É–∫–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Weights & Biases, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –±—ã—Ç—å –≤–∞–º –ø–æ–ª–µ–∑–Ω—ã.\n",
    "\n",
    "* [EfficientNet+Mixup+K-Fold using TF and wandb](https://www.kaggle.com/ayuraj/efficientnet-mixup-k-fold-using-tf-and-wandb)\n",
    "\n",
    "* [HPA: Segmentation Mask Visualization with W&B](https://www.kaggle.com/ayuraj/hpa-segmentation-mask-visualization-with-w-b)\n",
    "\n",
    "* [HPA: Multi-Label Classification with TF and W&B](https://www.kaggle.com/ayuraj/hpa-multi-label-classification-with-tf-and-w-b)\n",
    "\n",
    "* [üê¶BirdCLEF: Quick EDA with W&B](https://www.kaggle.com/ayuraj/birdclef-quick-eda-with-w-b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
